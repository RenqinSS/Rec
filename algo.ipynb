{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "algo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1xunUQ5o-Bz0e4eBzYNA1I8u3r7EDV18o",
      "authorship_tag": "ABX9TyNAf/nnpwquuOJj9HgQn2mm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "788ce3e287df4b7d800ee0ff17cdc966": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_88014f95e54e41c4ac17b5ea416f9258",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_84d92c88d99a4d5baa1e185384feea4b",
              "IPY_MODEL_12837a7403954d73a6223af8477b56e0"
            ]
          }
        },
        "88014f95e54e41c4ac17b5ea416f9258": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84d92c88d99a4d5baa1e185384feea4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_df37ae9cf853499d97e44287e3d7c9fa",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5f436fe6dff3417b869dbf2e9a7e5712"
          }
        },
        "12837a7403954d73a6223af8477b56e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_957d2b87eb5841bba3d7782a416f530c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [01:09&lt;00:00, 17.38s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d4d65751ce84f7ebefe0c744e0da0fc"
          }
        },
        "df37ae9cf853499d97e44287e3d7c9fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5f436fe6dff3417b869dbf2e9a7e5712": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "957d2b87eb5841bba3d7782a416f530c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d4d65751ce84f7ebefe0c744e0da0fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RenqinSS/Rec/blob/main/algo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QHbnc90G16y"
      },
      "source": [
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "SEED = 45\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "seed_everything(SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsF5tZ_aYVHY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07a0ae5c-6109-45a5-9395-78dc49ab0981"
      },
      "source": [
        "!git clone https://github.com/dpoqb/wechat_big_data_baseline_pytorch.git\n",
        "\n",
        "!dir\n",
        "!mkdir data\n",
        "!unzip ./drive/MyDrive/wechat_algo_data1.zip -d ./data\n",
        "\n",
        "!pip install deepctr_torch\n",
        "\n",
        "import torch\n",
        "import os\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "for i in range(torch.cuda.device_count()):\n",
        "    print(torch.cuda.get_device_name(i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'wechat_big_data_baseline_pytorch'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 16 (delta 3), reused 5 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n",
            "drive  sample_data  wechat_big_data_baseline_pytorch\n",
            "Archive:  ./drive/MyDrive/wechat_algo_data1.zip\n",
            "   creating: ./data/wechat_algo_data1/\n",
            "  inflating: ./data/wechat_algo_data1/test_a.csv  \n",
            "  inflating: ./data/wechat_algo_data1/feed_info.csv  \n",
            "  inflating: ./data/wechat_algo_data1/feed_embeddings.csv  \n",
            "  inflating: ./data/wechat_algo_data1/README.md  \n",
            "  inflating: ./data/wechat_algo_data1/user_action.csv  \n",
            "  inflating: ./data/wechat_algo_data1/submit_demo_初赛a.csv  \n",
            "Collecting deepctr_torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/17/f392dfbaefdd6371335995c4f84cf3b5166cf907fdfa0aa4edc380fdfc5b/deepctr_torch-0.2.7-py3-none-any.whl (70kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from deepctr_torch) (2.5.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from deepctr_torch) (1.9.0+cu102)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from deepctr_torch) (0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from deepctr_torch) (4.41.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (3.12.4)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (0.12.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (1.6.3)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (1.34.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (2.5.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (2.5.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (0.4.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (1.12.1)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (3.7.4.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (0.36.2)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (1.1.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (1.19.5)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (1.12)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (1.1.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (0.2.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (3.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->deepctr_torch) (0.22.2.post1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow->deepctr_torch) (57.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->deepctr_torch) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->deepctr_torch) (0.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->deepctr_torch) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->deepctr_torch) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->deepctr_torch) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->deepctr_torch) (1.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->deepctr_torch) (0.6.1)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow->deepctr_torch) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->deepctr_torch) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->deepctr_torch) (1.4.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow->deepctr_torch) (4.5.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->deepctr_torch) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->deepctr_torch) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->deepctr_torch) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->deepctr_torch) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->deepctr_torch) (1.24.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->deepctr_torch) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->deepctr_torch) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->deepctr_torch) (4.2.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow->deepctr_torch) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->deepctr_torch) (3.1.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->deepctr_torch) (0.4.8)\n",
            "Installing collected packages: deepctr-torch\n",
            "Successfully installed deepctr-torch-0.2.7\n",
            "True\n",
            "Tesla V100-SXM2-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVqyM5mrYVJ2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "788ce3e287df4b7d800ee0ff17cdc966",
            "88014f95e54e41c4ac17b5ea416f9258",
            "84d92c88d99a4d5baa1e185384feea4b",
            "12837a7403954d73a6223af8477b56e0",
            "df37ae9cf853499d97e44287e3d7c9fa",
            "5f436fe6dff3417b869dbf2e9a7e5712",
            "957d2b87eb5841bba3d7782a416f530c",
            "7d4d65751ce84f7ebefe0c744e0da0fc"
          ]
        },
        "outputId": "4bc44036-2aa8-4d03-e167-04a704f8367f"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn.decomposition import PCA\n",
        "from collections import defaultdict\n",
        "\n",
        "import os\n",
        "os.chdir('/content/wechat_big_data_baseline_pytorch')\n",
        "\n",
        "\n",
        "# 存储数据的根目录\n",
        "ROOT_PATH = \"../data\"\n",
        "# 比赛数据集路径\n",
        "DATASET_PATH = ROOT_PATH + '/wechat_algo_data1/'\n",
        "# 训练集\n",
        "USER_ACTION = DATASET_PATH + \"user_action.csv\"\n",
        "FEED_INFO = DATASET_PATH + \"feed_info.csv\"\n",
        "FEED_EMBEDDINGS = DATASET_PATH + \"feed_embeddings.csv\"\n",
        "# 测试集\n",
        "TEST_FILE = DATASET_PATH + \"test_a.csv\"\n",
        "# 初赛待预测行为列表\n",
        "ACTION_LIST = [\"read_comment\", \"like\", \"click_avatar\", \"forward\"]\n",
        "FEA_COLUMN_LIST = [\"read_comment\", \"like\", \"click_avatar\", \"forward\", \"comment\", \"follow\", \"favorite\", \"device\"]\n",
        "FEA_FEED_LIST = ['feedid', 'authorid', 'videoplayseconds', 'bgm_song_id', 'bgm_singer_id', 'manual_tag_list']\n",
        "# 负样本下采样比例(负样本:正样本)\n",
        "ACTION_SAMPLE_RATE = {\"read_comment\": 4, \"like\": 4, \"click_avatar\": 4, \"forward\": 10, \"comment\": 10, \"follow\": 10, \"favorite\": 10}\n",
        "\n",
        "def process_embed(train):\n",
        "    feed_embed_array = np.zeros((train.shape[0], 512))\n",
        "    for i in tqdm(range(train.shape[0])):\n",
        "        x = train.loc[i, 'feed_embedding']\n",
        "        if x != np.nan and x != '':\n",
        "            y = [float(i) for i in str(x).strip().split(\" \")]\n",
        "        else:\n",
        "            y = np.zeros((512,)).tolist()\n",
        "        feed_embed_array[i] += y\n",
        "    temp = pd.DataFrame(columns=[f\"embed{i}\" for i in range(512)], data=feed_embed_array)\n",
        "    train = pd.concat((train, temp), axis=1)\n",
        "    return train\n",
        "\n",
        "def proc_tag(df, name='manual_tag_list', thre=5, max_len=5):\n",
        "    stat = defaultdict(int)\n",
        "\n",
        "    for row in df[name]:\n",
        "        if isinstance(row, str):\n",
        "            for tag in row.strip().split(';'):\n",
        "                stat[tag] += 1\n",
        "\n",
        "    zero_tags = set([tag for tag in stat if stat[tag] < thre])  # 低于频次的 tag\n",
        "\n",
        "    def tag_func(row, max_len=max_len):\n",
        "        ret = []\n",
        "        if isinstance(row, str):\n",
        "            for tag in row.strip().split(';'):\n",
        "                ret.append(0 if tag in zero_tags else int(tag) + 1)\n",
        "        ret = ret[:max_len] + [0] * (max_len - len(ret))\n",
        "        return ' '.join([str(n) for n in ret])\n",
        "\n",
        "    df[name] = df[name].apply(tag_func)\n",
        "\n",
        "    tag_vocab_size = max([int(tag) for tag in stat]) + 2\n",
        "    print('%s: vocab_size == %d' % (name, tag_vocab_size))\n",
        "    return df\n",
        "\n",
        "def prepare_data():\n",
        "    feed_info_df = pd.read_csv(FEED_INFO)\n",
        "\n",
        "    feed_info_df = proc_tag(feed_info_df, name='manual_tag_list', thre=5, max_len=5)\n",
        "\n",
        "    user_action_df = pd.read_csv(USER_ACTION)[[\"userid\", \"date_\", \"feedid\",] + FEA_COLUMN_LIST]\n",
        "    \n",
        "    feed_info_df = feed_info_df[FEA_FEED_LIST]\n",
        "\n",
        "    test = pd.read_csv(TEST_FILE)\n",
        "\n",
        "    # add feed feature\n",
        "    train = pd.merge(user_action_df, feed_info_df, on='feedid', how='left')\n",
        "    test = pd.merge(test, feed_info_df, on='feedid', how='left')\n",
        "    test[\"videoplayseconds\"] = np.log(test[\"videoplayseconds\"] + 1.0)\n",
        "    test.to_csv(ROOT_PATH + f'/test_data.csv', index=False)\n",
        "    for action in tqdm(ACTION_LIST):\n",
        "        print(f\"prepare data for {action}\")\n",
        "        tmp = train.drop_duplicates(['userid', 'feedid', action], keep='last')\n",
        "        df_neg = tmp[tmp[action] == 0]\n",
        "        df_neg = df_neg.sample(frac=1.0 / ACTION_SAMPLE_RATE[action], random_state=SEED, replace=False)\n",
        "        df_all = pd.concat([df_neg, tmp[tmp[action] == 1]])\n",
        "        df_all[\"videoplayseconds\"] = np.log(df_all[\"videoplayseconds\"] + 1.0)\n",
        "        df_all.to_csv(ROOT_PATH + f'/train_data_for_{action}.csv', index=False)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    prepare_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "manual_tag_list: vocab_size == 354\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:82: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "788ce3e287df4b7d800ee0ff17cdc966",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "prepare data for read_comment\n",
            "prepare data for like\n",
            "prepare data for click_avatar\n",
            "prepare data for forward\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8hU0hEnElyG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nOwfT3flUQ8"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "n_dim = 32\n",
        "feed_embed = pd.read_csv(FEED_EMBEDDINGS)\n",
        "feed_embed['feed_embedding'] = feed_embed['feed_embedding'].apply(lambda row: [float(x) for x in row.strip().split()])\n",
        "pca = PCA(n_components=n_dim)\n",
        "pca_emb = pca.fit_transform(feed_embed['feed_embedding'].tolist())\n",
        "feed_embed['pca_emb'] = list(pca_emb)\n",
        "feed_embed = feed_embed[['feedid', 'pca_emb']]\n",
        "# feed_embed.drop(['feed_embedding'], axis=1).to_csv(\"/content/drive/MyDrive/pca_emb%d.csv\" % n_dim, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuGc8tdlmSMk"
      },
      "source": [
        "from numba import njit\n",
        "from scipy.stats import rankdata\n",
        "\n",
        "\n",
        "@njit\n",
        "def _auc(actual, pred_ranks):\n",
        "    n_pos = np.sum(actual)\n",
        "    n_neg = len(actual) - n_pos\n",
        "    return (np.sum(pred_ranks[actual == 1]) - n_pos*(n_pos+1)/2) / (n_pos*n_neg)\n",
        "\n",
        "\n",
        "def fast_auc(actual, predicted):\n",
        "    # https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/208031\n",
        "    pred_ranks = rankdata(predicted)\n",
        "    return _auc(actual, pred_ranks)\n",
        "\n",
        "\n",
        "def uAUC(labels, preds, user_id_list):\n",
        "    user_pred = defaultdict(lambda: [])\n",
        "    user_truth = defaultdict(lambda: [])\n",
        "    for idx, truth in enumerate(labels):\n",
        "        user_id = user_id_list[idx]\n",
        "        pred = preds[idx]\n",
        "        truth = labels[idx]\n",
        "        user_pred[user_id].append(pred)\n",
        "        user_truth[user_id].append(truth)\n",
        "\n",
        "    user_flag = defaultdict(lambda: False)\n",
        "    for user_id in set(user_id_list):\n",
        "        truths = user_truth[user_id]\n",
        "        flag = False\n",
        "        # 若全是正样本或全是负样本，则flag为False\n",
        "        for i in range(len(truths) - 1):\n",
        "            if truths[i] != truths[i + 1]:\n",
        "                flag = True\n",
        "                break\n",
        "        user_flag[user_id] = flag\n",
        "\n",
        "    total_auc = 0.0\n",
        "    size = 0.0\n",
        "    for user_id in user_flag:\n",
        "        if user_flag[user_id]:\n",
        "            auc = fast_auc(np.asarray(user_truth[user_id]), np.asarray(user_pred[user_id]))\n",
        "            total_auc += auc \n",
        "            size += 1.0\n",
        "    user_auc = float(total_auc)/size\n",
        "    return user_auc\n",
        "\n",
        "\n",
        "def compute_weighted_score(score_dict, weight_dict):\n",
        "    score = 0.0\n",
        "    weight_sum = 0.0\n",
        "    for action in score_dict:\n",
        "        weight = float(weight_dict[action])\n",
        "        score += weight*score_dict[action]\n",
        "        weight_sum += weight\n",
        "    score /= float(weight_sum)\n",
        "    score = round(score, 6)\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJYGuMEzaDqv"
      },
      "source": [
        "sparse_2_dim = {\n",
        "    'userid': 8,\n",
        "    'feedid': 8,\n",
        "    'authorid': 8,\n",
        "    'bgm_song_id': 8,\n",
        "    'bgm_singer_id': 8,\n",
        "}\n",
        "\n",
        "dense_2_dim = {\n",
        "    'videoplayseconds': 1,\n",
        "    'pca_emb': 32,\n",
        "    #'w2v': 8 * 3\n",
        "}\n",
        "\n",
        "var_2_dim = {\n",
        "    'manual_tag_list': {'dim': 8, 'vocab_size': 354},\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUUpRzOuYVO-"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from collections import defaultdict\n",
        "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names\n",
        "from deepctr_torch.models.deepfm import *\n",
        "from deepctr_torch.models.basemodel import *\n",
        "\n",
        "\n",
        "class MyBaseModel(BaseModel):\n",
        "\n",
        "    def fit(self, x, y, batch_size, val_data=None, epochs=1, verbose=1, mode='offline'):\n",
        "        x = [x[feature] for feature in self.feature_index]  # type(x) = dict\n",
        "        for i in range(len(x)):\n",
        "            x[i] = np.array(x[i].tolist())\n",
        "            if len(x[i].shape) == 1:\n",
        "                x[i] = np.expand_dims(x[i], axis=1)\n",
        "\n",
        "        val_x, val_y = [], []\n",
        "        if mode == 'offline':\n",
        "            val_x, val_y = val_data\n",
        "            val_uids = val_x['userid'].tolist()\n",
        "            val_x = [val_x[feature] for feature in self.feature_index]\n",
        "        \n",
        "        train_tensor_data = Data.TensorDataset(torch.from_numpy(np.concatenate(x, axis=-1)), torch.from_numpy(y))\n",
        "        train_loader = DataLoader(dataset=train_tensor_data, shuffle=True, batch_size=batch_size)\n",
        "        sample_num = len(train_tensor_data)\n",
        "        steps_per_epoch = (sample_num - 1) // batch_size + 1\n",
        "\n",
        "        # Train\n",
        "        print(\"Train on {0} samples, validate on {1} samples, {2} steps per epoch\".format(len(train_tensor_data), len(val_y), steps_per_epoch))\n",
        "        epoch_logs = defaultdict(dict)\n",
        "        model = self.train()\n",
        "        for epoch in range(epochs):\n",
        "            start_time = time.time()\n",
        "            loss_epoch = 0\n",
        "            total_loss_epoch = 0\n",
        "            train_result = defaultdict(list)\n",
        "            for _, (x_train, y_train) in tqdm(enumerate(train_loader)):\n",
        "                x = x_train.to(self.device).float()\n",
        "                y = y_train.to(self.device).float()\n",
        "\n",
        "                y_pred = model(x).squeeze()\n",
        "\n",
        "                self.optim.zero_grad()\n",
        "                loss = self.loss_func(y_pred, y.squeeze(), reduction='sum')\n",
        "                total_loss = loss + self.get_regularization_loss() + self.aux_loss\n",
        "\n",
        "                loss_epoch += loss.item()\n",
        "                total_loss_epoch += total_loss.item()\n",
        "                total_loss.backward()\n",
        "                self.optim.step()\n",
        "\n",
        "                for name, func in self.metrics.items():\n",
        "                    try:\n",
        "                        temp = func(y.cpu().data.numpy(), y_pred.cpu().data.numpy().astype(\"float64\"))\n",
        "                    except:\n",
        "                        temp = 0\n",
        "                    finally:\n",
        "                        train_result[name].append(temp)\n",
        "\n",
        "            # Add logs\n",
        "            logs = {}\n",
        "            logs[\"loss\"] = total_loss_epoch / sample_num\n",
        "            for name, result in train_result.items():\n",
        "                logs[name] = np.sum(result) / steps_per_epoch\n",
        "\n",
        "            if mode == 'offline':\n",
        "                eval_result = self.evaluate(val_x, val_y, val_uids, batch_size)\n",
        "                for name, result in eval_result.items():\n",
        "                    logs[\"val_\" + name] = result\n",
        "            \n",
        "            print('Epoch {0}/{1}, {2}s'.format(epoch + 1, epochs, int(time.time() - start_time)))\n",
        "            eval_str = \"loss: {0: .4f}\".format(logs[\"loss\"])\n",
        "            for name in logs:\n",
        "                eval_str += \" - \" + name + \": {0: .4f}\".format(logs[name])\n",
        "            print(eval_str)\n",
        "            epoch_logs[epoch+1] = logs\n",
        "        return epoch_logs\n",
        "\n",
        "    def evaluate(self, x, y, uids, batch_size=256):\n",
        "        preds = self.predict(x, batch_size)\n",
        "        eval_result = {}\n",
        "        for name, metric_fun in self.metrics.items():\n",
        "            eval_result[name] = metric_fun(y, preds)\n",
        "        eval_result['uAUC'] = uAUC(y.squeeze(), preds.squeeze(), uids)\n",
        "\n",
        "        return eval_result\n",
        "\n",
        "    def predict(self, x, batch_size=256):\n",
        "        model = self.eval()\n",
        "        if isinstance(x, dict):\n",
        "            x = [x[feature] for feature in self.feature_index]\n",
        "        for i in range(len(x)):\n",
        "            x[i] = np.array(x[i].tolist())\n",
        "            if len(x[i].shape) == 1:\n",
        "                x[i] = np.expand_dims(x[i], axis=1)\n",
        "\n",
        "        tensor_data = Data.TensorDataset(torch.from_numpy(np.concatenate(x, axis=-1)))\n",
        "        test_loader = DataLoader(dataset=tensor_data, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "        pred_ans = []\n",
        "        with torch.no_grad():\n",
        "            for _, x_test in enumerate(test_loader):\n",
        "                x = x_test[0].to(self.device).float()\n",
        "                y_pred = model(x).cpu().data.numpy()\n",
        "                pred_ans.append(y_pred)\n",
        "\n",
        "        return np.concatenate(pred_ans).astype(\"float64\")\n",
        "\n",
        "class MyDeepFM(MyBaseModel):\n",
        "    def __init__(self,\n",
        "                 linear_feature_columns, dnn_feature_columns,\n",
        "                 dense_map = None, dnn_hidden_units=(256, 128),\n",
        "                 l2_reg_linear=0.00001, l2_reg_embedding=0.00001, l2_reg_dnn=0, init_std=0.0001, seed=1024,\n",
        "                 dnn_dropout=0., dnn_activation='relu', dnn_use_bn=True, task='binary', device='cpu'):\n",
        "\n",
        "        super(MyDeepFM, self).__init__(linear_feature_columns, dnn_feature_columns, l2_reg_linear=l2_reg_linear,\n",
        "                                     l2_reg_embedding=l2_reg_embedding, init_std=init_std, seed=seed, task=task,\n",
        "                                     device=device)\n",
        "\n",
        "        # dense map\n",
        "        dense_map = {}\n",
        "        self.dense_map = dense_map\n",
        "        self.dense_map_dict = dict([(name, nn.Linear(dense_2_dim[name], dense_map[name], bias=False).to(device)) for name in dense_map])\n",
        "        dim_delta = sum([dense_map[name] - dense_2_dim[name] for name in dense_map])\n",
        "\n",
        "        # dnn tower\n",
        "        self.dnn = DNN(self.compute_input_dim(dnn_feature_columns) + dim_delta, dnn_hidden_units,\n",
        "                        activation=dnn_activation, l2_reg=l2_reg_dnn, dropout_rate=dnn_dropout, use_bn=dnn_use_bn,\n",
        "                        init_std=init_std, seed=seed, device=device)\n",
        "        self.dnn_linear = nn.Linear(dnn_hidden_units[-1], 1, bias=False).to(device)\n",
        "        self.add_regularization_weight(filter(lambda x: 'weight' in x[0] and 'bn' not in x[0], self.dnn.named_parameters()), l2=l2_reg_dnn)\n",
        "        self.add_regularization_weight(self.dnn_linear.weight, l2=l2_reg_dnn)\n",
        "\n",
        "        self.to(device)\n",
        "\n",
        "    def forward(self, X):\n",
        "        sparse_embedding_list, dense_value_list = self.input_from_feature_columns(X, self.dnn_feature_columns, self.embedding_dict) # 5*[512,1,4], 1*[512,1]\n",
        "        \n",
        "        # lr\n",
        "        logit = self.linear_model(X)\n",
        "        \n",
        "        # fm\n",
        "        fm_input = torch.cat(sparse_embedding_list, dim=1)\n",
        "        square_of_sum = torch.pow(torch.sum(fm_input, dim=1, keepdim=True), 2)\n",
        "        sum_of_square = torch.sum(fm_input * fm_input, dim=1, keepdim=True)\n",
        "        logit += 0.5 * torch.sum(square_of_sum - sum_of_square, dim=2, keepdim=False)\n",
        "\n",
        "        # dense map\n",
        "        dense_names = [fc.name for fc in self.dnn_feature_columns if isinstance(fc, DenseFeat)]\n",
        "        tmp = []\n",
        "        for name, tensor in zip (dense_names, dense_value_list):\n",
        "            if name in self.dense_map_dict:\n",
        "                tensor = self.dense_map_dict[name](tensor)\n",
        "            tmp.append(tensor)\n",
        "        dense_value_list = tmp\n",
        "\n",
        "        # dnn tower\n",
        "        sparse_dnn_input = torch.flatten(torch.cat(sparse_embedding_list, dim=-1), start_dim=1)\n",
        "        dense_dnn_input = torch.flatten(torch.cat(dense_value_list, dim=-1), start_dim=1)\n",
        "        dnn_input = torch.cat([sparse_dnn_input, dense_dnn_input], dim=-1)\n",
        "        logit += self.dnn_linear(self.dnn(dnn_input))\n",
        "        \n",
        "        return self.out(logit)\n",
        "\n",
        "\n",
        "mode = 'online'  # online\n",
        "if __name__ == \"__main__\":\n",
        "    submit = pd.read_csv(ROOT_PATH + '/test_data.csv')[['userid', 'feedid']]\n",
        "    logs = {}\n",
        "    for action in ACTION_LIST:\n",
        "        print('*** train for %s ***' % action)\n",
        "\n",
        "        USE_FEAT = ['userid', 'feedid', 'device', action] + FEA_FEED_LIST[1:]\n",
        "        train = pd.read_csv(ROOT_PATH + f'/train_data_for_{action}.csv')[['date_'] + USE_FEAT]\n",
        "\n",
        "        # TODO: sampling\n",
        "        # train = train.sample(frac=0.1, random_state=42).reset_index(drop=True)\n",
        "        print(\"positive ratio:\", sum((train[action] == 1) * 1) / train.shape[0])\n",
        "        \n",
        "        test = pd.read_csv(ROOT_PATH + '/test_data.csv')[[i for i in USE_FEAT if i != action]]\n",
        "        test[action] = 0\n",
        "        test['date_'] = 15\n",
        "        test = test[['date_'] + USE_FEAT]\n",
        "        data = pd.concat((train, test)).reset_index(drop=True)\n",
        "\n",
        "        # universal embedding\n",
        "        data = pd.merge(data, feed_embed, on='feedid', how='left')\n",
        "        data['pca_emb'] = [e if isinstance(e, np.ndarray) else np.zeros((32)) for e in data['pca_emb']]\n",
        "        data['manual_tag_list'] = data['manual_tag_list'].apply(lambda row: np.array([int(x) for x in row.split()]))\n",
        "\n",
        "        # features\n",
        "        sparse_features = list(sparse_2_dim.keys())\n",
        "        dense_features = list(dense_2_dim.keys())\n",
        "        var_features = list(var_2_dim.keys())\n",
        "        print('sparse_features: ', sparse_features)\n",
        "        print('dense_features: ', dense_features)\n",
        "        print('var_features: ', var_features)\n",
        "\n",
        "        data[sparse_features] = data[sparse_features].fillna(0)\n",
        "        data[dense_features] = data[dense_features].fillna(0)\n",
        "\n",
        "        # 1.Label Encoding for sparse features,and do simple Transformation for dense features\n",
        "        for feat in sparse_features:\n",
        "            lbe = LabelEncoder()\n",
        "            data[feat] = lbe.fit_transform(data[feat])\n",
        "        # mms = MinMaxScaler(feature_range=(0, 1))\n",
        "        # data[dense_features] = mms.fit_transform(data[dense_features])\n",
        "\n",
        "        # 2.count #unique features for each sparse field,and record dense feature field name\n",
        "        varlen_feature_columns = [VarLenSparseFeat(SparseFeat(feat, vocabulary_size=var_2_dim[feat]['vocab_size'], embedding_dim=var_2_dim[feat]['dim']), maxlen=5, combiner='sum') for feat in var_features]\n",
        "        \n",
        "        fixlen_feature_columns = [SparseFeat(feat, data[feat].nunique(), sparse_2_dim[feat]) for feat in sparse_features] + [DenseFeat(feat, dense_2_dim[feat]) for feat in dense_features]\n",
        "        dnn_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
        "        linear_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
        "\n",
        "        feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
        "\n",
        "        # 3.generate input data for model\n",
        "        train, test = data.iloc[:train.shape[0]].reset_index(drop=True), data.iloc[train.shape[0]:].reset_index(drop=True)\n",
        "        if mode == 'offline':\n",
        "            train_idxes, eval_idxes = train['date_'] != 14, train['date_'] == 14\n",
        "            train, eval = train[train_idxes].drop(['date_'], axis=1), train[eval_idxes].drop(['date_'], axis=1)\n",
        "        if mode == 'online':\n",
        "            train = train.drop(['date_'], axis=1)\n",
        "            eval = train.head()  # fake\n",
        "        test = test.drop(['date_'], axis=1)\n",
        "\n",
        "        train_x = {name: train[name] for name in feature_names}\n",
        "        eval_x  = {name: eval[name]  for name in feature_names}\n",
        "        test_x  = {name: test[name]  for name in feature_names}\n",
        "\n",
        "        # 4.Define Model,train,predict and evaluate\n",
        "        model = MyDeepFM(\n",
        "            linear_feature_columns=linear_feature_columns, \n",
        "            dnn_feature_columns=dnn_feature_columns,\n",
        "            task='binary', l2_reg_embedding=1e-1, device='cuda:0' if torch.cuda.is_available() else 'cpu', seed=SEED)\n",
        "        model.compile(\"adagrad\", \"binary_crossentropy\", metrics=[\"binary_crossentropy\", \"auc\"])\n",
        "        \n",
        "        act_logs = model.fit(train_x, train[[action]].values, val_data=(eval_x, eval[[action]].values), batch_size=512, epochs=2, mode=mode)\n",
        "        logs[action] = act_logs\n",
        "\n",
        "        # online\n",
        "        submit[action] = model.predict(test_x, 128)\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    # weighted uAUC\n",
        "    if mode == 'offline':\n",
        "        score_dict = {}\n",
        "        for act in logs:\n",
        "            act_logs = logs[act]\n",
        "            score_dict[act] = act_logs[max(act_logs.keys())]['val_uAUC']\n",
        "        weight_dict = {\"read_comment\": 4.0, \"like\": 3.0, \"click_avatar\": 2.0, \"forward\": 1.0, \"favorite\": 1.0, \"comment\": 1.0, \"follow\": 1.0}\n",
        "        weighted_uAUC = compute_weighted_score(score_dict, weight_dict)\n",
        "        print(score_dict)\n",
        "        print('weighted_uAUC: ', weighted_uAUC)\n",
        "\n",
        "    # online\n",
        "    submit.to_csv(\"./submit_2_45.csv\", index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qg_8D33ZER0Z"
      },
      "source": [
        "todo:\n",
        "  不同的action使用不同的epoch\n",
        "  seed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyzYd7eje2Tg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "d98761ff-fcbb-43f2-de79-abde085c56a8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-9063a9f0e032>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXovUg_GfEFR",
        "outputId": "b13900ae-89db-4482-bb86-2f42c521763b"
      },
      "source": [
        "int(k[1:-1].strip().split(',')[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZwlmrxkfEIK"
      },
      "source": [
        "p = data['manual_tag_list'].apply(lambda row: np.array([int(x) for x in row.split()]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viCCScX4Cdiq",
        "outputId": "4aba587f-c29f-4cc1-f4ea-fb734bd45304"
      },
      "source": [
        "p[0].dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('int64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGF54fEqCdmR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOHzOnDaJ9xd"
      },
      "source": [
        "# baseline\n",
        "{'read_comment': 0.6102415130979689, 'like': 0.6055234369612766, 'click_avatar': 0.7059927976309249, 'forward': 0.6832353813536607}\n",
        "weighted_uAUC:  0.635276\n",
        "\n",
        "# dnn_dropout = 0.1\n",
        "{'read_comment': 0.6094100217906185, 'like': 0.6052801328988395, 'click_avatar': 0.7059140934189055, 'forward': 0.6846734262464789}\n",
        "weighted_uAUC:  0.634998\n",
        "\n",
        "# 256, 128, 128\n",
        "{'read_comment': 0.613116787160124, 'like': 0.6062583852548347, 'click_avatar': 0.7058735217580193, 'forward': 0.6769030704770939}\n",
        "weighted_uAUC:  0.635989\n",
        "\n",
        "# epoch = 2\n",
        "{'read_comment': 0.6117841889858322, 'like': 0.6089919743022709, 'click_avatar': 0.7138421964649098, 'forward': 0.6829949302549756}\n",
        "weighted_uAUC:  0.638479\n",
        "\n",
        "# sparse dim = 8, epoch = 2 (new baseline)\n",
        "{'read_comment': 0.6126884118803656, 'like': 0.6078158393185238, 'click_avatar': 0.7141126528216767, 'forward': 0.6923154125787877}\n",
        "weighted_uAUC:  0.639474\n",
        "\n",
        "# 删除了对 videoplayseconds 的归一化(new baseline)\n",
        "{'read_comment': 0.6150373746448982, 'like': 0.6087792274162345, 'click_avatar': 0.7137088800810096, 'forward': 0.6919173648006157}\n",
        "weighted_uAUC:  0.640582\n",
        "\n",
        "# add feed embedding 32(new baseline)\n",
        "{'read_comment': 0.6231230935993682, 'like': 0.6162679088683002, 'click_avatar': 0.7128391281987229, 'forward': 0.6951917541544708}\n",
        "weighted_uAUC:  0.646217\n",
        "\n",
        "# add feed embedding 64\n",
        "{'read_comment': 0.6179610910963779, 'like': 0.617180918593666, 'click_avatar': 0.7121687727167492, 'forward': 0.6969728833664359}\n",
        "weighted_uAUC:  0.64447\n",
        "\n",
        "# sparse dim = 12\n",
        "{'read_comment': 0.6152862366363533, 'like': 0.6172504324924313, 'click_avatar': 0.7100718453099804, 'forward': 0.701999472669805}\n",
        "weighted_uAUC:  0.643504\n",
        "\n",
        "# baseline 的重复实验，线上 0.656674\n",
        "{'read_comment': 0.6220072250372239, 'like': 0.6181791275945606, 'click_avatar': 0.7129768375663601, 'forward': 0.6987107057431032}\n",
        "weighted_uAUC:  0.646723\n",
        "\n",
        "# (256, 128, 64)\n",
        "{'read_comment': 0.6176483873668901, 'like': 0.6170515088013665, 'click_avatar': 0.713929279701119, 'forward': 0.6961728898267605}\n",
        "weighted_uAUC:  0.644578\n",
        "\n",
        "# dnn_use_bn = True(new baseline) 线上 0.65576\n",
        "{'read_comment': 0.6269150887735059, 'like': 0.6245276506750953, 'click_avatar': 0.715901103365852, 'forward': 0.7038550482328185}\n",
        "weighted_uAUC:  0.65169\n",
        "\n",
        "# dropout = 0.1\n",
        "{'read_comment': 0.6261901395330384, 'like': 0.6239817428964435, 'click_avatar': 0.7163355996839406, 'forward': 0.6963938852580808}\n",
        "weighted_uAUC:  0.650577\n",
        "\n",
        "# baseline 重复实验\n",
        "{'read_comment': 0.6296090935187716, 'like': 0.621418106767897, 'click_avatar': 0.7168717294762987, 'forward': 0.6967281458462133}\n",
        "weighted_uAUC:  0.651316\n",
        "\n",
        "# 先使用linear对ue降维（32->16），再接入dnn\n",
        "{'read_comment': 0.6227016241604177, 'like': 0.6199456756568217, 'click_avatar': 0.7143073328988507, 'forward': 0.6791432406166807}\n",
        "weighted_uAUC:  0.64584\n",
        "\n",
        "# ue(32->4) dnn_use_bn = True\n",
        "{'read_comment': 0.6214967487996874, 'like': 0.6117349933619828, 'click_avatar': 0.7123781829253133, 'forward': 0.6907462327570015}\n",
        "weighted_uAUC:  0.643669\n",
        "\n",
        "# ue(32->8) dnn_use_bn = True\n",
        "{'read_comment': 0.6255372000774586, 'like': 0.6099148843168334, 'click_avatar': 0.7147080055545442, 'forward': 0.6913280305289646}\n",
        "weighted_uAUC:  0.645264\n",
        "\n",
        "# ue(32->16) dnn_use_bn = True\n",
        "{'read_comment': 0.6230882216710302, 'like': 0.620136770671566, 'click_avatar': 0.716609921279133, 'forward': 0.6855595234090964}\n",
        "weighted_uAUC:  0.647154\n",
        "\n",
        "# ue(32->32) dnn_use_bn = True\n",
        "{'read_comment': 0.6244980658541014, 'like': 0.6178982426111442, 'click_avatar': 0.7149869209063016, 'forward': 0.7032611484183776}\n",
        "weighted_uAUC:  0.648492\n",
        "\n",
        "# ue(32) dnn_use_bn = True * 2\n",
        "{'read_comment': 0.6268910782755379, 'like': 0.6222017679020581, 'click_avatar': 0.7150488812479852, 'forward': 0.6991933553474539}\n",
        "weighted_uAUC:  0.650346\n",
        "\n",
        "# ue(32) dnn_use_bn = True 换gpu跑\n",
        "{'read_comment': 0.6244744632801036, 'like': 0.6220399203865046, 'click_avatar': 0.7144416351024233, 'forward': 0.6968944127096272}\n",
        "weighted_uAUC:  0.64898\n",
        "\n",
        "# ue(32) dnn_use_bn = True 换gpu跑\n",
        "{'read_comment': 0.6275061489685031, 'like': 0.6229652888075203, 'click_avatar': 0.7143199406719899, 'forward': 0.6981564617860107}\n",
        "weighted_uAUC:  0.650572\n",
        "\n",
        "# ue(32) dnn_use_bn = False\n",
        "{'read_comment': 0.621629670929673, 'like': 0.6172394906951797, 'click_avatar': 0.7138702099995802, 'forward': 0.6971143776259561}\n",
        "weighted_uAUC:  0.646309\n",
        "\n",
        "# ue(32->32) dnn_use_bn = False\n",
        "{'read_comment': 0.6185276618440073, 'like': 0.6170842463943023, 'click_avatar': 0.7135048353197133, 'forward': 0.6971910507462337}\n",
        "weighted_uAUC:  0.644956\n",
        "\n",
        "# 采样 4 4 4 10 (new baseline)\n",
        "{'read_comment': 0.6313212962172534, 'like': 0.6220075992585066, 'click_avatar': 0.7143381748417214, 'forward': 0.6978311251747286}\n",
        "weighted_uAUC:  0.651782\n",
        "\n",
        "# + device\n",
        "{'read_comment': 0.6244486461941755, 'like': 0.6263065400087143, 'click_avatar': 0.7067274451536654, 'forward': 0.7078156246005303}\n",
        "weighted_uAUC:  0.649798\n",
        "\n",
        "{'read_comment': 0.6239386227276458, 'like': 0.6246523621908081, 'click_avatar': 0.7127589873646121, 'forward': 0.7021687370818925}\n",
        "weighted_uAUC:  0.64974\n",
        "\n",
        "# baseline\n",
        "{'read_comment': 0.6288471047258013, 'like': 0.6219350043589409, 'click_avatar': 0.7146902582599014, 'forward': 0.6918359172388889}\n",
        "weighted_uAUC:  0.650241\n",
        "\n",
        "# seed = 80 split_seed = 42\n",
        "{'read_comment': 0.6242634094879379, 'like': 0.6264243440165063, 'click_avatar': 0.7118413185387293, 'forward': 0.6945659928938664}\n",
        "weighted_uAUC:  0.649458\n",
        "\n",
        "# seed = 80\n",
        "{'read_comment': 0.6204573895103794, 'like': 0.62392994828236, 'click_avatar': 0.7235837537540227, 'forward': 0.6789320461307407}\n",
        "weighted_uAUC:  0.647972\n",
        "\n",
        "seed = 81\n",
        "{'read_comment': 0.6224667184141309, 'like': 0.6232470714913648, 'click_avatar': 0.710962678982845, 'forward': 0.6922917821851972}\n",
        "weighted_uAUC:  0.647383\n",
        "\n",
        "# seed 41 42 43 44 45 avg online\n",
        "{'read_comment': 0.644098, 'like': 0.63073, 'click_avatar': 0.733325, 'forward': 0.697216}\n",
        "weighted_uAUC:  0.663245\n",
        "\n",
        "\n",
        "# seed = 41 ; with manual_tags_dim = 8\n",
        "{'read_comment': 0.6248747741666473, 'like': 0.6202584290770113, 'click_avatar': 0.7195684676287956, 'forward': 0.695015289241745}\n",
        "weighted_uAUC:  0.649443\n",
        "\n",
        "### 换gpu ###\n",
        "# seed = 42 ; with manual_tags_dim = 8\n",
        "{'read_comment': 0.6326313492611053, 'like': 0.6238611589799947, 'click_avatar': 0.7190238030791103, 'forward': 0.7043097908858788}\n",
        "weighted_uAUC:  0.654447\n",
        "\n",
        "# 线上 42\n",
        "{'read_comment': 0.636948, 'like': 0.623838, 'click_avatar': 0.727661, 'forward': 0.693742}\n",
        "weighted_uAUC:  0.656837\n",
        "\n",
        "# 线上 seed 41 42 43 44 45 avg\n",
        "{'read_comment': 0.646524, 'like': 0.629584, 'click_avatar': 0.733393, 'forward': 0.698964}\n",
        "weighted_uAUC:  0.66406\n",
        "\n",
        "# seed = 42 ; w/o manual_tags_dim = 8\n",
        "{'read_comment': 0.6227764240658794, 'like': 0.6238680596273618, 'click_avatar': 0.7145209265367466, 'forward': 0.7000066937625322}\n",
        "weighted_uAUC:  0.649176"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj_uQPc8neKm"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dTb--Kxnfkv"
      },
      "source": [
        "USE_FEAT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egxa8Ee47yDZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}