{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "algo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1xunUQ5o-Bz0e4eBzYNA1I8u3r7EDV18o",
      "authorship_tag": "ABX9TyMqpQF1LwDQNXa5/NkOeRom",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RenqinSS/Rec/blob/main/algo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsF5tZ_aYVHY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ccbda3e-f8ee-4d57-dda5-015099242ed9"
      },
      "source": [
        "!git clone https://github.com/dpoqb/wechat_big_data_baseline_pytorch.git\n",
        "\n",
        "!dir\n",
        "!mkdir data\n",
        "!unzip ./drive/MyDrive/wechat_algo_data1.zip -d ./data\n",
        "\n",
        "!pip install deepctr_torch\n",
        "\n",
        "import torch\n",
        "import os\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "for i in range(torch.cuda.device_count()):\n",
        "    print(torch.cuda.get_device_name(i))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'wechat_big_data_baseline_pytorch'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 16 (delta 3), reused 5 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n",
            "drive  sample_data  wechat_big_data_baseline_pytorch\n",
            "Archive:  ./drive/MyDrive/wechat_algo_data1.zip\n",
            "   creating: ./data/wechat_algo_data1/\n",
            "  inflating: ./data/wechat_algo_data1/test_a.csv  \n",
            "  inflating: ./data/wechat_algo_data1/feed_info.csv  \n",
            "  inflating: ./data/wechat_algo_data1/feed_embeddings.csv  \n",
            "  inflating: ./data/wechat_algo_data1/README.md  \n",
            "  inflating: ./data/wechat_algo_data1/user_action.csv  \n",
            "  inflating: ./data/wechat_algo_data1/submit_demo_初赛a.csv  \n",
            "Collecting deepctr_torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/17/f392dfbaefdd6371335995c4f84cf3b5166cf907fdfa0aa4edc380fdfc5b/deepctr_torch-0.2.7-py3-none-any.whl (70kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from deepctr_torch) (1.9.0+cu102)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from deepctr_torch) (2.5.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from deepctr_torch) (4.41.1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from deepctr_torch) (0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->deepctr_torch) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (3.12.4)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (2.5.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (3.3.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (1.1.2)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (1.12)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (0.4.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (0.36.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (0.2.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (1.15.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (1.6.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (1.12.1)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (0.12.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (1.34.1)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (3.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (2.5.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow->deepctr_torch) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->deepctr_torch) (0.22.2.post1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow->deepctr_torch) (57.0.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow->deepctr_torch) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->deepctr_torch) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->deepctr_torch) (1.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->deepctr_torch) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->deepctr_torch) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->deepctr_torch) (0.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->deepctr_torch) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->deepctr_torch) (1.0.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->deepctr_torch) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->deepctr_torch) (1.4.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow->deepctr_torch) (4.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->deepctr_torch) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->deepctr_torch) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->deepctr_torch) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->deepctr_torch) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->deepctr_torch) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->deepctr_torch) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->deepctr_torch) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->deepctr_torch) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow->deepctr_torch) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->deepctr_torch) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->deepctr_torch) (3.1.1)\n",
            "Installing collected packages: deepctr-torch\n",
            "Successfully installed deepctr-torch-0.2.7\n",
            "True\n",
            "Tesla V100-SXM2-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVqyM5mrYVJ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "000f10e3-ba51-41e8-eb4f-a2fc565ca26d"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import os\n",
        "os.chdir('/content/wechat_big_data_baseline_pytorch')\n",
        "\n",
        "\n",
        "# 存储数据的根目录\n",
        "ROOT_PATH = \"../data\"\n",
        "# 比赛数据集路径\n",
        "DATASET_PATH = ROOT_PATH + '/wechat_algo_data1/'\n",
        "# 训练集\n",
        "USER_ACTION = DATASET_PATH + \"user_action.csv\"\n",
        "FEED_INFO = DATASET_PATH + \"feed_info.csv\"\n",
        "FEED_EMBEDDINGS = DATASET_PATH + \"feed_embeddings.csv\"\n",
        "# 测试集\n",
        "TEST_FILE = DATASET_PATH + \"test_a.csv\"\n",
        "# 初赛待预测行为列表\n",
        "ACTION_LIST = [\"read_comment\", \"like\", \"click_avatar\", \"forward\"]\n",
        "FEA_COLUMN_LIST = [\"read_comment\", \"like\", \"click_avatar\", \"forward\", \"comment\", \"follow\", \"favorite\"]\n",
        "FEA_FEED_LIST = ['feedid', 'authorid', 'videoplayseconds', 'bgm_song_id', 'bgm_singer_id']\n",
        "# 负样本下采样比例(负样本:正样本)\n",
        "ACTION_SAMPLE_RATE = {\"read_comment\": 5, \"like\": 5, \"click_avatar\": 5, \"forward\": 10, \"comment\": 10, \"follow\": 10, \"favorite\": 10}\n",
        "\n",
        "def process_embed(train):\n",
        "    feed_embed_array = np.zeros((train.shape[0], 512))\n",
        "    for i in tqdm(range(train.shape[0])):\n",
        "        x = train.loc[i, 'feed_embedding']\n",
        "        if x != np.nan and x != '':\n",
        "            y = [float(i) for i in str(x).strip().split(\" \")]\n",
        "        else:\n",
        "            y = np.zeros((512,)).tolist()\n",
        "        feed_embed_array[i] += y\n",
        "    temp = pd.DataFrame(columns=[f\"embed{i}\" for i in range(512)], data=feed_embed_array)\n",
        "    train = pd.concat((train, temp), axis=1)\n",
        "    return train\n",
        "\n",
        "def prepare_data():\n",
        "    feed_info_df = pd.read_csv(FEED_INFO)\n",
        "    user_action_df = pd.read_csv(USER_ACTION)[[\"userid\", \"date_\", \"feedid\"] + FEA_COLUMN_LIST]\n",
        "    \n",
        "    feed_info_df = feed_info_df[FEA_FEED_LIST]\n",
        "\n",
        "    test = pd.read_csv(TEST_FILE)\n",
        "\n",
        "    # add feed feature\n",
        "    train = pd.merge(user_action_df, feed_info_df, on='feedid', how='left')\n",
        "    test = pd.merge(test, feed_info_df, on='feedid', how='left')\n",
        "    test[\"videoplayseconds\"] = np.log(test[\"videoplayseconds\"] + 1.0)\n",
        "    test.to_csv(ROOT_PATH + f'/test_data.csv', index=False)\n",
        "    for action in tqdm(ACTION_LIST):\n",
        "        print(f\"prepare data for {action}\")\n",
        "        tmp = train.drop_duplicates(['userid', 'feedid', action], keep='last')\n",
        "        df_neg = tmp[tmp[action] == 0]\n",
        "        df_neg = df_neg.sample(frac=1.0 / ACTION_SAMPLE_RATE[action], random_state=42, replace=False)\n",
        "        df_all = pd.concat([df_neg, tmp[tmp[action] == 1]])\n",
        "        df_all[\"videoplayseconds\"] = np.log(df_all[\"videoplayseconds\"] + 1.0)\n",
        "        df_all.to_csv(ROOT_PATH + f'/train_data_for_{action}.csv', index=False)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    prepare_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "prepare data for read_comment\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 1/4 [00:11<00:34, 11.46s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "prepare data for like\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 2/4 [00:22<00:22, 11.22s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "prepare data for click_avatar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 3/4 [00:32<00:10, 10.97s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "prepare data for forward\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:38<00:00,  9.70s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nOwfT3flUQ8"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "n_dim = 32\n",
        "feed_embed = pd.read_csv(FEED_EMBEDDINGS)\n",
        "feed_embed['feed_embedding'] = feed_embed['feed_embedding'].apply(lambda row: [float(x) for x in row.strip().split()])\n",
        "pca = PCA(n_components=n_dim)\n",
        "pca_emb = pca.fit_transform(feed_embed['feed_embedding'].tolist())\n",
        "feed_embed['pca_emb'] = list(pca_emb)\n",
        "feed_embed = feed_embed[['feedid', 'pca_emb']]\n",
        "# feed_embed.drop(['feed_embedding'], axis=1).to_csv(\"/content/drive/MyDrive/pca_emb%d.csv\" % n_dim, index=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU-T2POFdDwH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3UbgxlMdD4t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuGc8tdlmSMk"
      },
      "source": [
        "from numba import njit\n",
        "from scipy.stats import rankdata\n",
        "\n",
        "\n",
        "@njit\n",
        "def _auc(actual, pred_ranks):\n",
        "    n_pos = np.sum(actual)\n",
        "    n_neg = len(actual) - n_pos\n",
        "    return (np.sum(pred_ranks[actual == 1]) - n_pos*(n_pos+1)/2) / (n_pos*n_neg)\n",
        "\n",
        "\n",
        "def fast_auc(actual, predicted):\n",
        "    # https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/208031\n",
        "    pred_ranks = rankdata(predicted)\n",
        "    return _auc(actual, pred_ranks)\n",
        "\n",
        "\n",
        "def uAUC(labels, preds, user_id_list):\n",
        "    user_pred = defaultdict(lambda: [])\n",
        "    user_truth = defaultdict(lambda: [])\n",
        "    for idx, truth in enumerate(labels):\n",
        "        user_id = user_id_list[idx]\n",
        "        pred = preds[idx]\n",
        "        truth = labels[idx]\n",
        "        user_pred[user_id].append(pred)\n",
        "        user_truth[user_id].append(truth)\n",
        "\n",
        "    user_flag = defaultdict(lambda: False)\n",
        "    for user_id in set(user_id_list):\n",
        "        truths = user_truth[user_id]\n",
        "        flag = False\n",
        "        # 若全是正样本或全是负样本，则flag为False\n",
        "        for i in range(len(truths) - 1):\n",
        "            if truths[i] != truths[i + 1]:\n",
        "                flag = True\n",
        "                break\n",
        "        user_flag[user_id] = flag\n",
        "\n",
        "    total_auc = 0.0\n",
        "    size = 0.0\n",
        "    for user_id in user_flag:\n",
        "        if user_flag[user_id]:\n",
        "            auc = fast_auc(np.asarray(user_truth[user_id]), np.asarray(user_pred[user_id]))\n",
        "            total_auc += auc \n",
        "            size += 1.0\n",
        "    user_auc = float(total_auc)/size\n",
        "    return user_auc\n",
        "\n",
        "\n",
        "def compute_weighted_score(score_dict, weight_dict):\n",
        "    score = 0.0\n",
        "    weight_sum = 0.0\n",
        "    for action in score_dict:\n",
        "        weight = float(weight_dict[action])\n",
        "        score += weight*score_dict[action]\n",
        "        weight_sum += weight\n",
        "    score /= float(weight_sum)\n",
        "    score = round(score, 6)\n",
        "    return score"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJYGuMEzaDqv"
      },
      "source": [
        "sparse_2_dim = {\n",
        "    'userid': 8,\n",
        "    'feedid': 8,\n",
        "    'authorid': 8,\n",
        "    'bgm_song_id': 8,\n",
        "    'bgm_singer_id': 8,\n",
        "}\n",
        "\n",
        "dense_2_dim = {\n",
        "    'videoplayseconds': 1,\n",
        "    'pca_emb': 32,\n",
        "}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUUpRzOuYVO-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bf10e36-d31f-4426-b396-a29741e7cd70"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names\n",
        "from deepctr_torch.models.deepfm import *\n",
        "from deepctr_torch.models.basemodel import *\n",
        "\n",
        "\n",
        "class MyBaseModel(BaseModel):\n",
        "\n",
        "    def fit(self, x, y, batch_size, val_data=None, epochs=1, verbose=1, mode='offline'):\n",
        "        x = [x[feature] for feature in self.feature_index]  # type(x) = dict\n",
        "        for i in range(len(x)):\n",
        "            x[i] = np.array(x[i].tolist())\n",
        "            if len(x[i].shape) == 1:\n",
        "                x[i] = np.expand_dims(x[i], axis=1)\n",
        "\n",
        "        val_x, val_y = [], []\n",
        "        if mode == 'offline':\n",
        "            val_x, val_y = val_data\n",
        "            val_uids = val_x['userid'].tolist()\n",
        "            val_x = [val_x[feature] for feature in self.feature_index]\n",
        "\n",
        "        train_tensor_data = Data.TensorDataset(torch.from_numpy(np.concatenate(x, axis=-1)), torch.from_numpy(y))\n",
        "        train_loader = DataLoader(dataset=train_tensor_data, shuffle=True, batch_size=batch_size)\n",
        "        sample_num = len(train_tensor_data)\n",
        "        steps_per_epoch = (sample_num - 1) // batch_size + 1\n",
        "\n",
        "        # Train\n",
        "        print(\"Train on {0} samples, validate on {1} samples, {2} steps per epoch\".format(len(train_tensor_data), len(val_y), steps_per_epoch))\n",
        "        epoch_logs = defaultdict(dict)\n",
        "        model = self.train()\n",
        "        for epoch in range(epochs):\n",
        "            start_time = time.time()\n",
        "            loss_epoch = 0\n",
        "            total_loss_epoch = 0\n",
        "            train_result = defaultdict(list)\n",
        "            for _, (x_train, y_train) in tqdm(enumerate(train_loader)):\n",
        "                x = x_train.to(self.device).float()\n",
        "                y = y_train.to(self.device).float()\n",
        "\n",
        "                y_pred = model(x).squeeze()\n",
        "\n",
        "                self.optim.zero_grad()\n",
        "                loss = self.loss_func(y_pred, y.squeeze(), reduction='sum')\n",
        "                total_loss = loss + self.get_regularization_loss() + self.aux_loss\n",
        "\n",
        "                loss_epoch += loss.item()\n",
        "                total_loss_epoch += total_loss.item()\n",
        "                total_loss.backward()\n",
        "                self.optim.step()\n",
        "\n",
        "                for name, func in self.metrics.items():\n",
        "                    train_result[name].append(func(y.cpu().data.numpy(), y_pred.cpu().data.numpy().astype(\"float64\")))\n",
        "\n",
        "            # Add logs\n",
        "            logs = {}\n",
        "            logs[\"loss\"] = total_loss_epoch / sample_num\n",
        "            for name, result in train_result.items():\n",
        "                logs[name] = np.sum(result) / steps_per_epoch\n",
        "\n",
        "            if mode == 'offline':\n",
        "                eval_result = self.evaluate(val_x, val_y, val_uids, batch_size)\n",
        "                for name, result in eval_result.items():\n",
        "                    logs[\"val_\" + name] = result\n",
        "            \n",
        "            print('Epoch {0}/{1}, {2}s'.format(epoch + 1, epochs, int(time.time() - start_time)))\n",
        "            eval_str = \"loss: {0: .4f}\".format(logs[\"loss\"])\n",
        "            for name in logs:\n",
        "                eval_str += \" - \" + name + \": {0: .4f}\".format(logs[name])\n",
        "            print(eval_str)\n",
        "            epoch_logs[epoch+1] = logs\n",
        "        return epoch_logs\n",
        "\n",
        "    def evaluate(self, x, y, uids, batch_size=256):\n",
        "        preds = self.predict(x, batch_size)\n",
        "        eval_result = {}\n",
        "        for name, metric_fun in self.metrics.items():\n",
        "            eval_result[name] = metric_fun(y, preds)\n",
        "        eval_result['uAUC'] = uAUC(y.squeeze(), preds.squeeze(), uids)\n",
        "\n",
        "        return eval_result\n",
        "\n",
        "    def predict(self, x, batch_size=256):\n",
        "        model = self.eval()\n",
        "        if isinstance(x, dict):\n",
        "            x = [x[feature] for feature in self.feature_index]\n",
        "        for i in range(len(x)):\n",
        "            x[i] = np.array(x[i].tolist())\n",
        "            if len(x[i].shape) == 1:\n",
        "                x[i] = np.expand_dims(x[i], axis=1)\n",
        "\n",
        "        tensor_data = Data.TensorDataset(torch.from_numpy(np.concatenate(x, axis=-1)))\n",
        "        test_loader = DataLoader(dataset=tensor_data, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "        pred_ans = []\n",
        "        with torch.no_grad():\n",
        "            for _, x_test in enumerate(test_loader):\n",
        "                x = x_test[0].to(self.device).float()\n",
        "                y_pred = model(x).cpu().data.numpy()\n",
        "                pred_ans.append(y_pred)\n",
        "\n",
        "        return np.concatenate(pred_ans).astype(\"float64\")\n",
        "\n",
        "class MyDeepFM(MyBaseModel):\n",
        "    def __init__(self,\n",
        "                 linear_feature_columns, dnn_feature_columns,\n",
        "                 dnn_hidden_units=(256, 128, 64),\n",
        "                 l2_reg_linear=0.00001, l2_reg_embedding=0.00001, l2_reg_dnn=0, init_std=0.0001, seed=1024,\n",
        "                 dnn_dropout=0, dnn_activation='relu', dnn_use_bn=False, task='binary', device='cpu'):\n",
        "\n",
        "        super(MyDeepFM, self).__init__(linear_feature_columns, dnn_feature_columns, l2_reg_linear=l2_reg_linear,\n",
        "                                     l2_reg_embedding=l2_reg_embedding, init_std=init_std, seed=seed, task=task,\n",
        "                                     device=device)\n",
        "\n",
        "        self.fm = FM()\n",
        "        self.dnn = DNN(self.compute_input_dim(dnn_feature_columns), dnn_hidden_units,\n",
        "                        activation=dnn_activation, l2_reg=l2_reg_dnn, dropout_rate=dnn_dropout, use_bn=dnn_use_bn,\n",
        "                        init_std=init_std, device=device)\n",
        "        self.dnn_linear = nn.Linear(dnn_hidden_units[-1], 1, bias=False).to(device)\n",
        "        self.add_regularization_weight(filter(lambda x: 'weight' in x[0] and 'bn' not in x[0], self.dnn.named_parameters()), l2=l2_reg_dnn)\n",
        "        self.add_regularization_weight(self.dnn_linear.weight, l2=l2_reg_dnn)\n",
        "\n",
        "        self.to(device)\n",
        "\n",
        "    def forward(self, X):\n",
        "        sparse_embedding_list, dense_value_list = self.input_from_feature_columns(X, self.dnn_feature_columns, self.embedding_dict) # 5*[512,1,4], 1*[512,1]\n",
        "        \n",
        "        # lr\n",
        "        logit = self.linear_model(X)\n",
        "        \n",
        "        # fm\n",
        "        fm_input = torch.cat(sparse_embedding_list, dim=1)\n",
        "        square_of_sum = torch.pow(torch.sum(fm_input, dim=1, keepdim=True), 2)\n",
        "        sum_of_square = torch.sum(fm_input * fm_input, dim=1, keepdim=True)\n",
        "        logit += 0.5 * torch.sum(square_of_sum - sum_of_square, dim=2, keepdim=False)\n",
        "\n",
        "        # dnn\n",
        "        sparse_dnn_input = torch.flatten(torch.cat(sparse_embedding_list, dim=-1), start_dim=1)\n",
        "        dense_dnn_input = torch.flatten(torch.cat(dense_value_list, dim=-1), start_dim=1)\n",
        "        dnn_input = torch.cat([sparse_dnn_input, dense_dnn_input], dim=-1)\n",
        "        logit += self.dnn_linear(self.dnn(dnn_input))\n",
        "        \n",
        "        return self.out(logit)\n",
        "\n",
        "\n",
        "mode = 'online'  # online\n",
        "if __name__ == \"__main__\":\n",
        "    submit = pd.read_csv(ROOT_PATH + '/test_data.csv')[['userid', 'feedid']]\n",
        "    logs = {}\n",
        "    for action in ACTION_LIST:\n",
        "        print('*** train for %s ***' % action)\n",
        "\n",
        "        USE_FEAT = ['userid', 'feedid', action] + FEA_FEED_LIST[1:]\n",
        "        train = pd.read_csv(ROOT_PATH + f'/train_data_for_{action}.csv')[['date_'] + USE_FEAT]\n",
        "\n",
        "        # TODO: sampling\n",
        "        # train = train.sample(frac=0.1, random_state=42).reset_index(drop=True)\n",
        "        print(\"positive ratio:\", sum((train[action] == 1) * 1) / train.shape[0])\n",
        "        \n",
        "        test = pd.read_csv(ROOT_PATH + '/test_data.csv')[[i for i in USE_FEAT if i != action]]\n",
        "        test[action] = 0\n",
        "        test['date_'] = 15\n",
        "        test = test[['date_'] + USE_FEAT]\n",
        "        data = pd.concat((train, test)).reset_index(drop=True)\n",
        "\n",
        "        # universal embedding\n",
        "        data = pd.merge(data, feed_embed, on='feedid', how='left')\n",
        "        data['pca_emb'] = [e if isinstance(e, np.ndarray) else np.zeros((32)) for e in data['pca_emb']]\n",
        "\n",
        "        # features\n",
        "        sparse_features = list(sparse_2_dim.keys())\n",
        "        dense_features = list(dense_2_dim.keys())\n",
        "        print('sparse_features: ', sparse_features)\n",
        "        print('dense_features: ', dense_features)\n",
        "\n",
        "        data[sparse_features] = data[sparse_features].fillna(0)\n",
        "        data[dense_features] = data[dense_features].fillna(0)\n",
        "\n",
        "        # 1.Label Encoding for sparse features,and do simple Transformation for dense features\n",
        "        for feat in sparse_features:\n",
        "            lbe = LabelEncoder()\n",
        "            data[feat] = lbe.fit_transform(data[feat])\n",
        "        # mms = MinMaxScaler(feature_range=(0, 1))\n",
        "        # data[dense_features] = mms.fit_transform(data[dense_features])\n",
        "\n",
        "        # 2.count #unique features for each sparse field,and record dense feature field name\n",
        "        fixlen_feature_columns = [SparseFeat(feat, data[feat].nunique(), sparse_2_dim[feat]) for feat in sparse_features] + [DenseFeat(feat, dense_2_dim[feat]) for feat in dense_features]\n",
        "        dnn_feature_columns = fixlen_feature_columns\n",
        "        linear_feature_columns = fixlen_feature_columns\n",
        "\n",
        "        feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
        "\n",
        "        # 3.generate input data for model\n",
        "        train, test = data.iloc[:train.shape[0]].reset_index(drop=True), data.iloc[train.shape[0]:].reset_index(drop=True)\n",
        "        if mode == 'offline':\n",
        "            train_idxes, eval_idxes = train['date_'] != 14, train['date_'] == 14\n",
        "            train, eval = train[train_idxes].drop(['date_'], axis=1), train[eval_idxes].drop(['date_'], axis=1)\n",
        "        if mode == 'online':\n",
        "            train = train.drop(['date_'], axis=1)\n",
        "            eval = train.head()  # fake\n",
        "        test = test.drop(['date_'], axis=1)\n",
        "\n",
        "        train_x = {name: train[name] for name in feature_names}\n",
        "        eval_x  = {name: eval[name]  for name in feature_names}\n",
        "        test_x  = {name: test[name]  for name in feature_names}\n",
        "\n",
        "        # 4.Define Model,train,predict and evaluate\n",
        "        model = MyDeepFM(\n",
        "            linear_feature_columns=linear_feature_columns, \n",
        "            dnn_feature_columns=dnn_feature_columns,\n",
        "            task='binary', l2_reg_embedding=1e-1, device='cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "        model.compile(\"adagrad\", \"binary_crossentropy\", metrics=[\"binary_crossentropy\", \"auc\"])\n",
        "        \n",
        "        act_logs = model.fit(train_x, train[[action]].values, val_data=(eval_x, eval[[action]].values), batch_size=512, epochs=2, mode=mode)\n",
        "        logs[action] = act_logs\n",
        "\n",
        "        # online\n",
        "        submit[action] = model.predict(test_x, 128)\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    # weighted uAUC\n",
        "    if mode == 'offline':\n",
        "        score_dict = {}\n",
        "        for act in logs:\n",
        "            act_logs = logs[act]\n",
        "            score_dict[act] = act_logs[max(act_logs.keys())]['val_uAUC']\n",
        "        weight_dict = {\"read_comment\": 4.0, \"like\": 3.0, \"click_avatar\": 2.0, \"forward\": 1.0, \"favorite\": 1.0, \"comment\": 1.0, \"follow\": 1.0}\n",
        "        weighted_uAUC = compute_weighted_score(score_dict, weight_dict)\n",
        "        print(score_dict)\n",
        "        print('weighted_uAUC: ', weighted_uAUC)\n",
        "\n",
        "    # online\n",
        "    submit.to_csv(\"./submit.csv\", index=False)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** train for read_comment ***\n",
            "positive ratio: 0.15565121499983292\n",
            "sparse_features:  ['userid', 'feedid', 'authorid', 'bgm_song_id', 'bgm_singer_id']\n",
            "dense_features:  ['videoplayseconds', 'pca_emb']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:00,  7.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1645885 samples, validate on 0 samples, 3215 steps per epoch\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3215it [00:37, 84.75it/s]\n",
            "1it [00:00,  7.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2, 37s\n",
            "loss:  0.2470 - loss:  0.2470 - binary_crossentropy:  0.2307 - auc:  0.9266\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3215it [00:37, 86.00it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/2, 37s\n",
            "loss:  0.2222 - loss:  0.2222 - binary_crossentropy:  0.2096 - auc:  0.9443\n",
            "*** train for like ***\n",
            "positive ratio: 0.11860030306914048\n",
            "sparse_features:  ['userid', 'feedid', 'authorid', 'bgm_song_id', 'bgm_singer_id']\n",
            "dense_features:  ['videoplayseconds', 'pca_emb']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:00,  7.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1591716 samples, validate on 0 samples, 3109 steps per epoch\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3109it [00:36, 85.34it/s]\n",
            "1it [00:00,  7.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2, 36s\n",
            "loss:  0.2769 - loss:  0.2769 - binary_crossentropy:  0.2605 - auc:  0.8493\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3109it [00:35, 87.18it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/2, 35s\n",
            "loss:  0.2558 - loss:  0.2558 - binary_crossentropy:  0.2428 - auc:  0.8764\n",
            "*** train for click_avatar ***\n",
            "positive ratio: 0.0371053151111731\n",
            "sparse_features:  ['userid', 'feedid', 'authorid', 'bgm_song_id', 'bgm_singer_id']\n",
            "dense_features:  ['videoplayseconds', 'pca_emb']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:00,  7.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1484127 samples, validate on 0 samples, 2899 steps per epoch\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2899it [00:34, 84.64it/s]\n",
            "1it [00:00,  7.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2, 34s\n",
            "loss:  0.1354 - loss:  0.1354 - binary_crossentropy:  0.1241 - auc:  0.8371\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2899it [00:34, 84.91it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/2, 34s\n",
            "loss:  0.1195 - loss:  0.1195 - binary_crossentropy:  0.1106 - auc:  0.8924\n",
            "*** train for forward ***\n",
            "positive ratio: 0.03752907526887493\n",
            "sparse_features:  ['userid', 'feedid', 'authorid', 'bgm_song_id', 'bgm_singer_id']\n",
            "dense_features:  ['videoplayseconds', 'pca_emb']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4it [00:00, 38.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 745049 samples, validate on 0 samples, 1456 steps per epoch\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1456it [00:16, 86.17it/s]\n",
            "1it [00:00,  7.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2, 16s\n",
            "loss:  0.1301 - loss:  0.1301 - binary_crossentropy:  0.1186 - auc:  0.8630\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1456it [00:17, 84.21it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/2, 17s\n",
            "loss:  0.1076 - loss:  0.1076 - binary_crossentropy:  0.0970 - auc:  0.9321\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOHzOnDaJ9xd"
      },
      "source": [
        "# baseline\n",
        "{'read_comment': 0.6102415130979689, 'like': 0.6055234369612766, 'click_avatar': 0.7059927976309249, 'forward': 0.6832353813536607}\n",
        "weighted_uAUC:  0.635276\n",
        "\n",
        "# dnn_dropout = 0.1\n",
        "{'read_comment': 0.6094100217906185, 'like': 0.6052801328988395, 'click_avatar': 0.7059140934189055, 'forward': 0.6846734262464789}\n",
        "weighted_uAUC:  0.634998\n",
        "\n",
        "# 256, 128, 128\n",
        "{'read_comment': 0.613116787160124, 'like': 0.6062583852548347, 'click_avatar': 0.7058735217580193, 'forward': 0.6769030704770939}\n",
        "weighted_uAUC:  0.635989\n",
        "\n",
        "# epoch = 2\n",
        "{'read_comment': 0.6117841889858322, 'like': 0.6089919743022709, 'click_avatar': 0.7138421964649098, 'forward': 0.6829949302549756}\n",
        "weighted_uAUC:  0.638479\n",
        "\n",
        "# sparse dim = 8, epoch = 2 (new baseline)\n",
        "{'read_comment': 0.6126884118803656, 'like': 0.6078158393185238, 'click_avatar': 0.7141126528216767, 'forward': 0.6923154125787877}\n",
        "weighted_uAUC:  0.639474\n",
        "\n",
        "# 删除了对 videoplayseconds 的归一化(new baseline)\n",
        "{'read_comment': 0.6150373746448982, 'like': 0.6087792274162345, 'click_avatar': 0.7137088800810096, 'forward': 0.6919173648006157}\n",
        "weighted_uAUC:  0.640582\n",
        "\n",
        "# add feed embedding 32(new baseline)\n",
        "{'read_comment': 0.6231230935993682, 'like': 0.6162679088683002, 'click_avatar': 0.7128391281987229, 'forward': 0.6951917541544708}\n",
        "weighted_uAUC:  0.646217\n",
        "\n",
        "# add feed embedding 64\n",
        "{'read_comment': 0.6179610910963779, 'like': 0.617180918593666, 'click_avatar': 0.7121687727167492, 'forward': 0.6969728833664359}\n",
        "weighted_uAUC:  0.64447\n",
        "\n",
        "# sparse dim = 12\n",
        "{'read_comment': 0.6152862366363533, 'like': 0.6172504324924313, 'click_avatar': 0.7100718453099804, 'forward': 0.701999472669805}\n",
        "weighted_uAUC:  0.643504\n",
        "\n",
        "# baseline 的重复实验\n",
        "{'read_comment': 0.6220072250372239, 'like': 0.6181791275945606, 'click_avatar': 0.7129768375663601, 'forward': 0.6987107057431032}\n",
        "weighted_uAUC:  0.646723"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}